{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting Korfball Results with Statistical Modelling: Dixon-Coles and Time-Weighting\n",
    "====\n",
    "*This post describes two popular improvements to the standard Poisson model for football predictions applied to korfball, collectively known as the Dixon-Coles model*\n",
    "\n",
    "[Rework of Predicting Football Results with Statistical Modelling: Dixon-Coles and Time-Weighting by David Sheehan](https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling-dixon-coles-and-time-weighting/)\n",
    "\n",
    "In an earlier post, I showed how to build a simple Poisson model to crudely predict the outcome of korfball matches. In the same way teams herald slight changes to their traditional plain coloured jerseys as ground breaking, I thought I'd show how the basic model could be tweaked and improved in order to achieve revolutionary status.\n",
    "\n",
    "The changes are motivated by a combination of intuition and statistics. The [Dixon-Coles](http://web.math.ku.dk/~rolf/teaching/thesis/DixonColes.pdf) model (named after the paper's authors) corrects for the basic model's underestimation of draws and it also incorporated a time component so that recent matches are considered more important in calculating average goals rate. This isn't a particularly nodel idea for a blog post. There are numerous implementations of the Dixon-Coles model out there. Like any niche statistical modelling exercise, however, they are mostly available in R. I strongly recommend the excellent [opisthokonta blog](http://opisthokonta.net/?cat=48), especially if you're interested in more advanced models. \n",
    "\n",
    "## Data\n",
    "\n",
    "We'll initially pull the match results for the EKL 2018/2019 season from [fixtureslive.com](https://w.fixtureslive.com/comp/57863/table/England-Korfball-National-League-EKL-Premier-Division-2018-19). This code is pretty much the same as last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Home Score</th>\n",
       "      <th>Away Team</th>\n",
       "      <th>Away Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bristol Thunder 1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Nomads 1</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kingfisher 1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>KV 1</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trojans 1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Tornadoes 1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cambridge Tigers 1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Birmingham City 1</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bec 1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Norwich Knights 1</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Home Team  Home Score          Away Team  Away Score\n",
       "0   Bristol Thunder 1        20.0           Nomads 1        21.0\n",
       "1        Kingfisher 1        23.0               KV 1        17.0\n",
       "2           Trojans 1        21.0        Tornadoes 1        14.0\n",
       "3  Cambridge Tigers 1        13.0  Birmingham City 1        15.0\n",
       "4               Bec 1        16.0  Norwich Knights 1        22.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import poisson, skellam\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "DATA_DIR = '../data/'\n",
    "ekl_1819 = pd.read_csv(DATA_DIR + 'all_data.csv', index_col=0)\n",
    "ekl_1819 = ekl_1819[ekl_1819.Season == '2018/19'][['Home Team', 'Home Score', 'Away Team', 'Away Score']].copy()\n",
    "ekl_1819.reset_index(inplace=True, drop=True)\n",
    "ekl_1819.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Poisson Model\n",
    "I won't spend too long on this model, as it was the subject of the [previous post](). Essentially, you treat the number of goals scored by each team as two independent Poisson distributions (henceforth called the Basic Poisson (BP) model). The shape of each distribution is determined by the average number of goals scored by that team. A little reminder on the mathematical definition of the Poisson distribution:\n",
    "\n",
    "$$P(x) = \\frac{e^{-\\lambda}\\lambda^{x}}{x!}, \\lambda > 0$$\n",
    "\n",
    "In our case, $\\lambda$ represents the team's average or expected goal scoring rate. The Poisson distribution is a decent approximation of a team's scoring frequency. All of the model's discussed here agree on this point; the diagreement centres on how to calculate $\\lambda_{\\text{home}}$ and $\\lambda_{\\text{away}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can formulate the model in mathematical terms:\n",
    "\n",
    "$$ P(X_{ij}=x, Y_{ij}=y) = \\frac{e^{-\\lambda}\\lambda^{x}}{x!}\\frac{e^{-\\mu}\\mu^y}{y!} \\\\\n",
    "\\text{where   } \\lambda=\\alpha_{i}\\beta_{j}\\gamma \\text{     }  \\mu=\\alpha_{j}\\beta{i} \n",
    "$$\n",
    "\n",
    "In this equation, $i$ and $j$ refer to the home and away teams, respectively; $\\alpha$ and $\\beta$ denote each team's attack and defensive strength, respectively, while $\\gamma$ represents the home advantage factor. So, we need to calculate $\\alpha$ and $\\beta$ for each team, as well as $\\gamma$ (the home field advantage term - it's the same value for every team). As this was explained in the [previous post](), I'll just show the model output.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                 Generalized Linear Model Regression Results                  \n",
    "==============================================================================\n",
    "Dep. Variable:                  goals   No. Observations:                  160\n",
    "Model:                            GLM   Df Residuals:                      140\n",
    "Model Family:                 Poisson   Df Model:                           19\n",
    "Link Function:                    log   Scale:                          1.0000\n",
    "Method:                          IRLS   Log-Likelihood:                -451.20\n",
    "Date:                Fri, 07 Aug 2020   Deviance:                       121.85\n",
    "Time:                        14:45:49   Pearson chi2:                     120.\n",
    "No. Iterations:                     4                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==================================================================================================\n",
    "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
    "--------------------------------------------------------------------------------------------------\n",
    "Intercept                          2.9782      0.083     35.977      0.000       2.816       3.140\n",
    "team[T.Birmingham City 1]         -0.6663      0.084     -7.914      0.000      -0.831      -0.501\n",
    "team[T.Bristol Thunder 1]         -0.3956      0.078     -5.057      0.000      -0.549      -0.242\n",
    "team[T.Cambridge Tigers 1]        -0.2381      0.078     -3.063      0.002      -0.390      -0.086\n",
    "team[T.KV 1]                      -0.2246      0.076     -2.949      0.003      -0.374      -0.075\n",
    "team[T.Kingfisher 1]              -0.1268      0.073     -1.742      0.081      -0.270       0.016\n",
    "team[T.Nomads 1]                  -0.1438      0.072     -1.986      0.047      -0.286      -0.002\n",
    "team[T.Norwich Knights 1]          0.0825      0.068      1.211      0.226      -0.051       0.216\n",
    "team[T.Tornadoes 1]                0.0738      0.070      1.059      0.290      -0.063       0.210\n",
    "team[T.Trojans 1]                  0.1269      0.069      1.849      0.064      -0.008       0.261\n",
    "opponent[T.Birmingham City 1]      0.3001      0.080      3.751      0.000       0.143       0.457\n",
    "opponent[T.Bristol Thunder 1]      0.4743      0.078      6.096      0.000       0.322       0.627\n",
    "opponent[T.Cambridge Tigers 1]     0.3871      0.082      4.749      0.000       0.227       0.547\n",
    "opponent[T.KV 1]                   0.3451      0.082      4.193      0.000       0.184       0.506\n",
    "opponent[T.Kingfisher 1]           0.2868      0.082      3.507      0.000       0.127       0.447\n",
    "opponent[T.Nomads 1]               0.4023      0.080      5.055      0.000       0.246       0.558\n",
    "opponent[T.Norwich Knights 1]      0.0297      0.087      0.341      0.733      -0.141       0.200\n",
    "opponent[T.Tornadoes 1]            0.1935      0.084      2.298      0.022       0.028       0.359\n",
    "opponent[T.Trojans 1]              0.0230      0.089      0.258      0.796      -0.152       0.198\n",
    "home                              -0.0338      0.034     -0.995      0.320      -0.100       0.033\n",
    "=================================================================================================="
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "poisson_model.predict(pd.DataFrame(data={'team': 'Bec 1', 'opponent': 'Cambridge Tigers 1',\n",
    "                                         'home': 1}, index=[1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1    27.979893\n",
    "dtype: float64"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "poisson_model.predict(pd.DataFrame(data={'team': 'Cambridge Tigers 1', 'opponent': 'Bec 1',\n",
    "                                         'home': 1}, index=[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0    14.973469\n",
    "dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, Bec (playing at home) would be expected to score 27.98 goals against Cambridge Tigers, while their opponents would get about 14.97 goals on average (I'm using the terms average and expected interchangeably). As each team is treated independently, we can construct a match score probability matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First [Published by Maher in 1982](http://www.90minut.pl/misc/maher.pdf), the BP model still serves a good starting point from which you can add features that more closely reflect the reality. That brings us onto the Dixon-Coles (DC) model. \n",
    "\n",
    "## Dixon-Coles Model\n",
    "In their [1997 paper](http://web.math.ku.dk/~rolf/teaching/thesis/DixonColes.pdf), Mark Dixon and Stuart Coles proposed two specific improvements to the BP model:\n",
    "\n",
    "- Introduce an interaction term to correct underestimated frequency of low scoring matches\n",
    "- Apply time decay component so that recent matches are weighted more strongly\n",
    "\n",
    "The authors claim that low score results in football (0-0, 1-0 and 1-1) are inherently under-reported by the BP model. In the paper, they provide some analysis that supports their case - though I wouldn't call their approach particularly rigorous. The matrix below shows the average difference between actual and model predicted scorelines for the 2005/06 English Premier League season all the way up to the to 2017/19 season. Green cells imply the model underestimated those scorelines, while red cells suggest overestimation - the colour strength indicated the level of disagreement.\n",
    "\n",
    "![image](https://dashee87.github.io/images/actual_model_diff.png)\n",
    "\n",
    "There does seem to be an issue arround low scoring draws, though it is less apparent with 1-0 and 0-1 results. The Dixon-Coles (DC) model applies a correction to the BP model. It can be written in these mathematical terms:\n",
    "\n",
    "\n",
    "$$\n",
    "P(X_{i,j}=x, Y_{j,i}=y)=\\tau_{\\lambda,\\mu}(x)\\frac{e^{-\\lambda}\\lambda^{x}}{x!}\\frac{e^{-\\mu}\\mu^{y}}{y!} \\\\\n",
    "\\text{where}\\quad\\lambda=\\alpha_{i}\\beta_{j}\\gamma \\quad \\mu=\\alpha_{j}\\beta_{i} \\\\\n",
    "\\tau_{\\lambda,\\mu}(x,y) = \n",
    "\\begin{cases}\n",
    "        1 - \\lambda\\mu\\rho  & \\text{if }x=y=0 \\\\\n",
    "        1 + \\lambda\\rho & \\text{if } x=1, y=0 \\\\\n",
    "        1 + \\mu\\rho & \\text{if } x=0, y=1 \\\\\n",
    "        1 - \\rho & \\text{if } x=y=1 \\\\\n",
    "        1 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The key difference over the BP model is the addition of the $\\tau$ (tau) function. It is highly dependent on teh $\\rho$ (rho) parameter, which controls the strength of the correction (note: setting $\\rho=0$ equated to the standard BP model). We can easily convert $\\tau_{\\lambda,\\mu}(x,y)$ to Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_correction(x, y, lambda_x, mu_y, rho):\n",
    "    if x==0 and y==0:\n",
    "        return 1 - (lambda_x * mu_y * rho)\n",
    "    elif x==0 and y==1:\n",
    "        return 1 + (lambda_x * rho)\n",
    "    elif x==1 and y==0:\n",
    "        return 1 + (mu_y * rho)\n",
    "    elif x==1 and y==1:\n",
    "        return 1 - rho\n",
    "    else:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, you can't just update your match score matrix with this funciton; you need to recalculate the various coefficients that go into the model. And unfortunately again, you can't just implement an off the shelf generalised linear model, as we did before. We have to construct the likelihood function and find the coefficients that maximise it - a technique known as [Maximum Likelihood Estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation). With matches index $k=1,...,N$ and corresponding scores $(x_{k},y_{k})$, this is the likelihood function that we seek to maximise:\n",
    "\n",
    "$$\n",
    "L(\\alpha_{i},\\beta_{i}, \\rho, \\gamma, i = 1,\\dots, n) = \\prod_{k=1}^{N}\\tau_{\\lambda_{k},\\mu_{k}}(x_{k},y_{k})\\frac{e^{-\\lambda}\\lambda^{x_k}}{x_k!}\\frac{e^{-\\mu}\\mu^{y_k}}{y_k!} \\\\\n",
    "\\text{where}\\quad \\lambda_k = \\alpha_{i(k)}\\beta_{j(k)}\\gamma \\quad \\mu_k=\\alpha_{j(k)}\\beta_{i(k)}\n",
    "$$\n",
    "\n",
    "In this equation, $i(k)$ and $j(k)$ respectively denote the indices of the home and away teams in match $k$. For a few [different reasons](https://www.quora.com/Why-is-log-likelihood-so-widely-used-in-Machine-Learning) (numerical precision, practicality, etc.), we'll actually maximise the log-likelihood function. As the logarithm is a strictly increasing function (i.e. $\\log(b) > \\log(a) \\ \\forall \\ b>a$), both likelihood functions are maximised at the same point. Also, recall that $\\log(a\\ b) = \\log(a) +  \\log(b)$. We can thus write the log-likelihood function in Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_log_like(x, y, alpha_x, beta_x, alpha_y, beta_y, rho, gamma):\n",
    "    lambda_x, mu_y = np.exp(alpha_x + beta_y + gamma), np.exp(alpha_y + beta_x)\n",
    "    return (np.log(rho_correction(x, y, lambda_x, mu_y, rho)) +\n",
    "            np.log(poisson.pmf(x, lambda_x)) + np.log(poisson.pmf(y, mu_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that `dc_log_like` included a transformation of $\\lambda$ and $\\mu$, where $\\lambda = \\exp(\\alpha_i+\\beta_j+\\gamma)$ and $\\mu = \\exp(\\alpha_j + \\beta_i)$, so that we're essentially trying to calculate expected log goals. This is equivalent to the log [link function](https://en.wikipedia.org/wiki/Generalized_linear_model) in the previous BP glm the maximization algorithm should be easier as $\\lambda, \\mu > 0 \\ \\forall \\ \\alpha,\\beta,\\gamma$. Non-positive lambdas are not compatible with a Poisson distribution, so this would return warnings and/or errors during implementation. \n",
    "\n",
    "We're now ready to find the parameters that maximise the log likelihood function. Basically, you design a function that takes a set of model parameters as an argument. You set some initial values and potentially include some constraints and select the appropriate optimisation algorithm. I've opted for scipy's [minimise function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) (a possible alternative is [fmin](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin.html) - note: the functions seek to minimise the negative log-likelihood). It employs a process analogous to gradient descent, so that the algorithm iteratively converges to the optimal parameter set. The computation can be quite slow as it's forced to approximate the derivatives. If you're not as lazy as me, you could potentially speed it up by [manually constructing the partial derivatives](https://projekter.aau.dk/projekter/files/14466581/AssessingTheNumberOfGoalsInSoccerMatches.pdf#page=61).\n",
    "\n",
    "In line with the original [Dixon Coles paper](http://web.math.ku.dk/~rolf/teaching/thesis/DixonColes.pdf) and the [opisthokonta blog](https://opisthokonta.net/?p=890), I've added the constraint that $\\frac{1}{n}\\sum_i\\alpha_i=1$ (i.e. the average attack strength value is 1). This step isn't strictly necessary, but it means that it should return a unique solution (otherwise, the model would suffer from overparameterisation and each execution would return different coefficients).\n",
    "\n",
    "Okay, we're ready to find the coefficients that maximise the log-likelihood function for the 2018/19 EKL season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_parameters(dataset, debug=False, init_vals=None, options={'disp': True, 'maxiter': 100},\n",
    "                     constraints = [{'type': 'eq', 'fun': lambda x: sum(x[:20])-20}], **kwargs):\n",
    "    teams = np.sort(dataset['Home Team'].unique())\n",
    "    # check for no weirdness in dataset\n",
    "    away_teams = np.sort(dataset['Away Team'].unique())\n",
    "    if not np.array_equal(teams, away_teams):\n",
    "        raise ValueError(\"Something's not right\")\n",
    "    n_teams = len(teams)\n",
    "    if init_vals is None:\n",
    "        # random initialisation of model parameters\n",
    "        init_vals = np.concatenate((np.random.uniform(0,1, (n_teams)), # attack strength\n",
    "                                    np.random.uniform(0, -1, (n_teams)), # defence strength\n",
    "                                    np.array([0, 1.0]) # rho (score correction), gamma (home advantage)\n",
    "                                   ))\n",
    "    def dc_log_like(x, y, alpha_x, beta_x, alpha_y, beta_y, rho, gamma):\n",
    "        lambda_x, mu_y = np.exp(alpha_x + beta_y + gamma), np.exp(alpha_y + beta_x)\n",
    "        return (np.log(rho_correction(x, y, lambda_x, mu_y, rho)) +\n",
    "                np.log(poisson.pmf(x, lambda_x)) + np.log(poisson.pmf(y, mu_y)))\n",
    "    \n",
    "    def estimate_parameters(params):\n",
    "        score_coefs = dict(zip(teams, params[:n_teams]))\n",
    "        defend_coefs = dict(zip(teams, params[n_teams: (2*n_teams)]))\n",
    "        rho, gamma = params[-2:]\n",
    "        log_like = [dc_log_like(row['Home Score'], row['Away Score'], \n",
    "                                score_coefs[row['Home Team']], defend_coefs[row['Home Team']],\n",
    "                                score_coefs[row['Away Team']], defend_coefs[row['Away Team']], rho, gamma)\n",
    "                    for row in dataset.itertuples()]\n",
    "        return -sum(log_like)\n",
    "    \n",
    "    opt_output = minimize(estimate_parameters, init_vals, options=options, constraints=constraints, **kwargs)\n",
    "    if debug:\n",
    "        # sort of hacky way to investigate the output of the optimisation process\n",
    "        return opt_output\n",
    "    else:\n",
    "        return dict(zip([\"attack_\"+team for team in teams] + \n",
    "                        [\"defence_\"+team for team in teams] +\n",
    "                        ['rho', 'home_adv'],\n",
    "                       opt_output.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
